Test 1D Laplacian of order 12000
Step 1: Create Mg handle and select devices 
	There are 8 GPUs 
	Device 0, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 1, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 2, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 3, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 4, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 5, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 6, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 7, NVIDIA A100-SXM4-80GB, cc 8.0 
step 2: Enable peer access.
	 Enable peer access from gpu 0 to gpu 1
	 Enable peer access from gpu 0 to gpu 2
	 Enable peer access from gpu 0 to gpu 3
	 Enable peer access from gpu 0 to gpu 4
	 Enable peer access from gpu 0 to gpu 5
	 Enable peer access from gpu 0 to gpu 6
	 Enable peer access from gpu 0 to gpu 7
	 Enable peer access from gpu 1 to gpu 0
	 Enable peer access from gpu 1 to gpu 2
	 Enable peer access from gpu 1 to gpu 3
	 Enable peer access from gpu 1 to gpu 4
	 Enable peer access from gpu 1 to gpu 5
	 Enable peer access from gpu 1 to gpu 6
	 Enable peer access from gpu 1 to gpu 7
	 Enable peer access from gpu 2 to gpu 0
	 Enable peer access from gpu 2 to gpu 1
	 Enable peer access from gpu 2 to gpu 3
	 Enable peer access from gpu 2 to gpu 4
	 Enable peer access from gpu 2 to gpu 5
	 Enable peer access from gpu 2 to gpu 6
	 Enable peer access from gpu 2 to gpu 7
	 Enable peer access from gpu 3 to gpu 0
	 Enable peer access from gpu 3 to gpu 1
	 Enable peer access from gpu 3 to gpu 2
	 Enable peer access from gpu 3 to gpu 4
	 Enable peer access from gpu 3 to gpu 5
	 Enable peer access from gpu 3 to gpu 6
	 Enable peer access from gpu 3 to gpu 7
	 Enable peer access from gpu 4 to gpu 0
	 Enable peer access from gpu 4 to gpu 1
	 Enable peer access from gpu 4 to gpu 2
	 Enable peer access from gpu 4 to gpu 3
	 Enable peer access from gpu 4 to gpu 5
	 Enable peer access from gpu 4 to gpu 6
	 Enable peer access from gpu 4 to gpu 7
	 Enable peer access from gpu 5 to gpu 0
	 Enable peer access from gpu 5 to gpu 1
	 Enable peer access from gpu 5 to gpu 2
	 Enable peer access from gpu 5 to gpu 3
	 Enable peer access from gpu 5 to gpu 4
	 Enable peer access from gpu 5 to gpu 6
	 Enable peer access from gpu 5 to gpu 7
	 Enable peer access from gpu 6 to gpu 0
	 Enable peer access from gpu 6 to gpu 1
	 Enable peer access from gpu 6 to gpu 2
	 Enable peer access from gpu 6 to gpu 3
	 Enable peer access from gpu 6 to gpu 4
	 Enable peer access from gpu 6 to gpu 5
	 Enable peer access from gpu 6 to gpu 7
	 Enable peer access from gpu 7 to gpu 0
	 Enable peer access from gpu 7 to gpu 1
	 Enable peer access from gpu 7 to gpu 2
	 Enable peer access from gpu 7 to gpu 3
	 Enable peer access from gpu 7 to gpu 4
	 Enable peer access from gpu 7 to gpu 5
	 Enable peer access from gpu 7 to gpu 6
Step 3: Allocate host memory A 
Step 4: Prepare 1D Laplacian 
Step 5: Create matrix descriptors for A and B 
Step 6: Allocate distributed matrices A and D 
Step 7: Prepare data on devices 
Step 8: Allocate workspace space 
	Allocate device workspace, lwork = 86400 
Step 9: Solve A*X = B by GETRF and GETRS 
Run 0 time used (s): 0.8924
Run 1 time used (s): 0.8578
Run 2 time used (s): 0.8465
Run 3 time used (s): 0.8561
Run 4 time used (s): 0.8535
Run 5 time used (s): 0.8524
Run 6 time used (s): 0.8538
Run 7 time used (s): 0.8564
Run 8 time used (s): 0.8530
Run 9 time used (s): 0.8523
Run 10 time used (s): 0.8528
Total time used (s): 9.4269
step 12: Free resources 
Test 1D Laplacian of order 12000
Step 1: Create Mg handle and select devices 
	There are 8 GPUs 
	Device 0, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 1, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 2, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 3, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 4, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 5, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 6, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 7, NVIDIA A100-SXM4-80GB, cc 8.0 
step 2: Enable peer access.
	 Enable peer access from gpu 0 to gpu 1
	 Enable peer access from gpu 0 to gpu 2
	 Enable peer access from gpu 0 to gpu 3
	 Enable peer access from gpu 0 to gpu 4
	 Enable peer access from gpu 0 to gpu 5
	 Enable peer access from gpu 0 to gpu 6
	 Enable peer access from gpu 0 to gpu 7
	 Enable peer access from gpu 1 to gpu 0
	 Enable peer access from gpu 1 to gpu 2
	 Enable peer access from gpu 1 to gpu 3
	 Enable peer access from gpu 1 to gpu 4
	 Enable peer access from gpu 1 to gpu 5
	 Enable peer access from gpu 1 to gpu 6
	 Enable peer access from gpu 1 to gpu 7
	 Enable peer access from gpu 2 to gpu 0
	 Enable peer access from gpu 2 to gpu 1
	 Enable peer access from gpu 2 to gpu 3
	 Enable peer access from gpu 2 to gpu 4
	 Enable peer access from gpu 2 to gpu 5
	 Enable peer access from gpu 2 to gpu 6
	 Enable peer access from gpu 2 to gpu 7
	 Enable peer access from gpu 3 to gpu 0
	 Enable peer access from gpu 3 to gpu 1
	 Enable peer access from gpu 3 to gpu 2
	 Enable peer access from gpu 3 to gpu 4
	 Enable peer access from gpu 3 to gpu 5
	 Enable peer access from gpu 3 to gpu 6
	 Enable peer access from gpu 3 to gpu 7
	 Enable peer access from gpu 4 to gpu 0
	 Enable peer access from gpu 4 to gpu 1
	 Enable peer access from gpu 4 to gpu 2
	 Enable peer access from gpu 4 to gpu 3
	 Enable peer access from gpu 4 to gpu 5
	 Enable peer access from gpu 4 to gpu 6
	 Enable peer access from gpu 4 to gpu 7
	 Enable peer access from gpu 5 to gpu 0
	 Enable peer access from gpu 5 to gpu 1
	 Enable peer access from gpu 5 to gpu 2
	 Enable peer access from gpu 5 to gpu 3
	 Enable peer access from gpu 5 to gpu 4
	 Enable peer access from gpu 5 to gpu 6
	 Enable peer access from gpu 5 to gpu 7
	 Enable peer access from gpu 6 to gpu 0
	 Enable peer access from gpu 6 to gpu 1
	 Enable peer access from gpu 6 to gpu 2
	 Enable peer access from gpu 6 to gpu 3
	 Enable peer access from gpu 6 to gpu 4
	 Enable peer access from gpu 6 to gpu 5
	 Enable peer access from gpu 6 to gpu 7
	 Enable peer access from gpu 7 to gpu 0
	 Enable peer access from gpu 7 to gpu 1
	 Enable peer access from gpu 7 to gpu 2
	 Enable peer access from gpu 7 to gpu 3
	 Enable peer access from gpu 7 to gpu 4
	 Enable peer access from gpu 7 to gpu 5
	 Enable peer access from gpu 7 to gpu 6
Step 3: Allocate host memory A 
Step 4: Prepare 1D Laplacian 
Step 5: Create matrix descriptors for A and B 
Step 6: Allocate distributed matrices A and D 
Step 7: Prepare data on devices 
Step 8: Allocate workspace space 
	Allocate device workspace, lwork = 86400 
Step 9: Solve A*X = B by GETRF and GETRS 
Run 0 time used (s): 0.8909
Run 1 time used (s): 0.8694
Run 2 time used (s): 0.8641
Run 3 time used (s): 0.8602
Run 4 time used (s): 0.8628
Run 5 time used (s): 0.8614
Run 6 time used (s): 0.8621
Run 7 time used (s): 0.8641
Run 8 time used (s): 0.8625
Run 9 time used (s): 0.8609
Run 10 time used (s): 0.8599
Total time used (s): 9.5184
step 12: Free resources 
