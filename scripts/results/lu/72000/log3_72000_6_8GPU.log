timeout: the monitored command dumped core
Test 1D Laplacian of order 72000
Step 1: Create Mg handle and select devices 
	There are 8 GPUs 
	Device 0, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 1, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 2, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 3, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 4, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 5, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 6, NVIDIA A100-SXM4-80GB, cc 8.0 
	Device 7, NVIDIA A100-SXM4-80GB, cc 8.0 
step 2: Enable peer access.
	 Enable peer access from gpu 0 to gpu 1
	 Enable peer access from gpu 0 to gpu 2
	 Enable peer access from gpu 0 to gpu 3
	 Enable peer access from gpu 0 to gpu 4
	 Enable peer access from gpu 0 to gpu 5
	 Enable peer access from gpu 0 to gpu 6
	 Enable peer access from gpu 0 to gpu 7
	 Enable peer access from gpu 1 to gpu 0
	 Enable peer access from gpu 1 to gpu 2
	 Enable peer access from gpu 1 to gpu 3
	 Enable peer access from gpu 1 to gpu 4
	 Enable peer access from gpu 1 to gpu 5
	 Enable peer access from gpu 1 to gpu 6
	 Enable peer access from gpu 1 to gpu 7
	 Enable peer access from gpu 2 to gpu 0
	 Enable peer access from gpu 2 to gpu 1
	 Enable peer access from gpu 2 to gpu 3
	 Enable peer access from gpu 2 to gpu 4
	 Enable peer access from gpu 2 to gpu 5
	 Enable peer access from gpu 2 to gpu 6
	 Enable peer access from gpu 2 to gpu 7
	 Enable peer access from gpu 3 to gpu 0
	 Enable peer access from gpu 3 to gpu 1
	 Enable peer access from gpu 3 to gpu 2
	 Enable peer access from gpu 3 to gpu 4
	 Enable peer access from gpu 3 to gpu 5
	 Enable peer access from gpu 3 to gpu 6
	 Enable peer access from gpu 3 to gpu 7
	 Enable peer access from gpu 4 to gpu 0
	 Enable peer access from gpu 4 to gpu 1
	 Enable peer access from gpu 4 to gpu 2
	 Enable peer access from gpu 4 to gpu 3
	 Enable peer access from gpu 4 to gpu 5
	 Enable peer access from gpu 4 to gpu 6
	 Enable peer access from gpu 4 to gpu 7
	 Enable peer access from gpu 5 to gpu 0
	 Enable peer access from gpu 5 to gpu 1
	 Enable peer access from gpu 5 to gpu 2
	 Enable peer access from gpu 5 to gpu 3
	 Enable peer access from gpu 5 to gpu 4
	 Enable peer access from gpu 5 to gpu 6
	 Enable peer access from gpu 5 to gpu 7
	 Enable peer access from gpu 6 to gpu 0
	 Enable peer access from gpu 6 to gpu 1
	 Enable peer access from gpu 6 to gpu 2
	 Enable peer access from gpu 6 to gpu 3
	 Enable peer access from gpu 6 to gpu 4
	 Enable peer access from gpu 6 to gpu 5
	 Enable peer access from gpu 6 to gpu 7
	 Enable peer access from gpu 7 to gpu 0
	 Enable peer access from gpu 7 to gpu 1
	 Enable peer access from gpu 7 to gpu 2
	 Enable peer access from gpu 7 to gpu 3
	 Enable peer access from gpu 7 to gpu 4
	 Enable peer access from gpu 7 to gpu 5
	 Enable peer access from gpu 7 to gpu 6
Step 3: Allocate host memory A 
Step 4: Prepare 1D Laplacian 
Step 5: Create matrix descriptors for A and B 
Step 6: Allocate distributed matrices A and D 
Step 7: Prepare data on devices 
Step 8: Allocate workspace space 
	Allocate device workspace, lwork = 466368 
Step 9: Solve A*X = B by GETRF and GETRS 
Run 0 time used (s): 33.4691
Run 1 time used (s): 33.4413
Run 2 time used (s): 33.4607
Run 3 time used (s): 33.4553
Run 4 time used (s): 33.4593
Run 5 time used (s): 33.4487
Run 6 time used (s): 33.4923
Run 7 time used (s): 33.4475
Run 8 time used (s): 33.4613
Run 9 time used (s): 33.4908
Run 10 time used (s): 33.4841
Total time used (s): 368.1102
step 12: Free resources 
